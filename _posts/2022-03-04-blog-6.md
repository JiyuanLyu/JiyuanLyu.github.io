---
layout: post
title: Blog Post 6
---

In this blog post, I'll develop and assess a fake news classifier using Tensorflow.

## Data Source

The data for this assignment comes from the article:
- Ahmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments. ISDDC 2017. Lecture Notes in Computer Science, vol 10618. Springer, Cham (pp. 127-138).

Prof. Chodrow accessed it from [Kaggle](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset) and have done a small amount of data cleaning and performed a train-test split.


# 1. Acquire Training Data

Since Prof. Chodrow has hosted a training data set at the below URL, I can read it into Python directly.

In this data, each row of the data corresponds to an article. 
1. The `title` column gives the title of the article.
2. The `text` column gives the full article text. 
3. The final column, called `fake`, is `0` if the article is `true` and `1` if the article contains `fake` news, as determined by the authors of the paper above.

```python
import pandas as pd
import tensorflow as tf

train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
df = pd.read_csv(train_url, header=0, index_col=0)
```

# 2. Make a Dataset

In this part, I'll write a function called `make_dataset()`. This function should do two things:
1. Remove **stopwords** from the article text and title. A stopword is a word that is usually considered to be uninformative, such as **“the,” “and,” or “but.”**
2. Construct and return a `tf.data.Dataset` with two inputs and one output. The input should be of the form `(title, text)`, and the output should consist only of the `fake` column.

Writing the function, I find help from the [StackOverFlow thread](https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe) and [lecture notes](https://nbviewer.org/github/PhilChodrow/PIC16B/blob/master/lectures/tf/tf-4.ipynb).

```python
# define the stopwords
from nltk.corpus import stopwords
stop = stopwords.words('english')

def make_dataset(df):
  """
  This function can remove the stopwords from the article text and title,
  and construct and return a dataset with two inputs and one output.

  Argument
  --------
  df: a pandas dataframe

  Result
  ------
  df: a tensorflow dataset
  """

  # remove the stopwords from text and title
  df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
  df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

  # construct the dataset
  ds = tf.data.Dataset.from_tensor_slices(
      (
          {
              "title": df[["title"]],
              "text": df[["text"]]
          },
          {
              "fake": df[["fake"]]
          }
      )
  )
  # batch for increasing the training speed
  ds.batch(100)

  return(ds)
```
Now, use the function above to constuct the primary dataset and split of 20% of it to use for validation.

```python
data = make_dataset(df)
data = data.shuffle(buffer_size = len(data))

train_size = int(0.8*len(data))
val_size   = int(0.2*len(data))

train = data.take(train_size)
val = data.skip(train_size).take(val_size)

len(train), len(val)
```

Excellent! We split our dataset into training set and validation!

### Base Rate

Now let's calculate the **base rate** for the data set. I'll determine the base rate by examining the labels on the training set.

```python
# examine the labels
labels_iterator= train.unbatch().map(lambda fake, label: label).as_numpy_iterator()
labels = list(labels_iterator)

# count the total fake numbers
total_fake = 0
for i in range(0, len(labels)):
  total_fake += labels[i]['fake']

# calculate the base rate
total_fake / len(labels)
```




    0.5241939974386102

As shown above, the **base rate** for the dataset is at about 52%. **Our model accuracy should achieve at least 52%**.

# 3. Create models

Now, I'll use `TensorFlow` models to offer a perspective on the following question:

>When detecting fake news, is it most effective to focus on only the title of the article, the full text of the article, or both?

In this part, I'll construct three models:
1. In the first model, use **only the article title** as an input.
2. In the second model, use **only the article text** as an input.
3. In the third model, use **both the article title** and **the article text** as input.

**Notation: Our best model should be able to consistently score at least 97% validation accuracy.**

## Standardization and Vectorization

Before modeling, I would like to do the standardization and vectorization. 

For this step, I find help from [this lecture notes](https://nbviewer.org/github/PhilChodrow/PIC16B/blob/master/lectures/tf/tf-3.ipynb).

```python
import re
import string

from tensorflow import keras
from tensorflow.keras import layers, Input, Model, utils, losses
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization

size_vocabulary = 2000

def standardization(input_data):
    lowercase = tf.strings.lower(input_data)
    no_punctuation = tf.strings.regex_replace(lowercase,
                                  '[%s]' % re.escape(string.punctuation),'')
    return no_punctuation 

vectorize_layer = TextVectorization(
    standardize=standardization,
    max_tokens=size_vocabulary, # only consider this many words
    output_mode='int',
    output_sequence_length=500) 

# Embedding
vectorize_layer.adapt(train.map(lambda x, y: x["text"]))
embedding = layers.Embedding(size_vocabulary, 3, name = "embedding")
```
Then, prepare the the text and title as inputs.
```python
# prepare the inputs

text_input = Input(
    shape = (1,), 
    name = "text",
    dtype = "string"
)

title_input = Input(
    shape = (1,), 
    name = "title",
    dtype = "string"
)
```
## Model 1: Only Article Title as Input

Great! Let's start contructing the first model with only the article title as input!

```python
# embedding the title
title_features = vectorize_layer(title_input)
title_features = embedding(title_features)

# use dropout to prevent the overfitting
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.GlobalAveragePooling1D()(title_features)
title_features = layers.Dropout(0.2)(title_features)
title_features = layers.Dense(32, activation='relu')(title_features)
title_output = layers.Dense(1, name = "fake")(title_features)
```

Now we build the `model1`, check its history and plot its accuracy.

```python
# building model
model1 = Model(
    inputs = [title_input],
    outputs = title_output
)

# compile model
model1.compile(optimizer = "adam",
               loss = losses.BinaryCrossentropy(from_logits=True),
               metrics=['accuracy']
)

# checking the model history
history1 = model1.fit(train,
                      validation_data=val,
                      epochs = 10)
```




    Epoch 1/10
    17959/17959 [==============================] - 86s 5ms/step - loss: 0.4227 - accuracy: 0.7402 - val_loss: 0.1611 - val_accuracy: 0.9292
    Epoch 2/10
    17959/17959 [==============================] - 45s 3ms/step - loss: 0.1724 - accuracy: 0.9272 - val_loss: 0.0981 - val_accuracy: 0.9637
    Epoch 3/10
    17959/17959 [==============================] - 57s 3ms/step - loss: 0.1354 - accuracy: 0.9462 - val_loss: 0.0886 - val_accuracy: 0.9668
    Epoch 4/10
    17959/17959 [==============================] - 86s 5ms/step - loss: 0.1255 - accuracy: 0.9492 - val_loss: 0.0647 - val_accuracy: 0.9757
    Epoch 5/10
    17959/17959 [==============================] - 53s 3ms/step - loss: 0.1250 - accuracy: 0.9482 - val_loss: 0.0914 - val_accuracy: 0.9586
    Epoch 6/10
    17959/17959 [==============================] - 59s 3ms/step - loss: 0.1149 - accuracy: 0.9551 - val_loss: 0.0812 - val_accuracy: 0.9728
    Epoch 7/10
    17959/17959 [==============================] - 72s 4ms/step - loss: 0.1102 - accuracy: 0.9577 - val_loss: 0.0995 - val_accuracy: 0.9548
    Epoch 8/10
    17959/17959 [==============================] - 57s 3ms/step - loss: 0.1091 - accuracy: 0.9571 - val_loss: 0.0846 - val_accuracy: 0.9706
    Epoch 9/10
    17959/17959 [==============================] - 51s 3ms/step - loss: 0.1083 - accuracy: 0.9563 - val_loss: 0.0843 - val_accuracy: 0.9603
    Epoch 10/10
    17959/17959 [==============================] - 51s 3ms/step - loss: 0.1089 - accuracy: 0.9562 - val_loss: 0.1199 - val_accuracy: 0.9456

Graph the accuracy of the training and validation, compared `model1` with the **base rate 52%**.

```python
from matplotlib import pyplot as plt
# Plot the training accuracy
plt.plot(history1.history['accuracy'], label = "Training Set Accuracy")

# Plot the validation accuracy
plt.plot(history1.history['val_accuracy'], label = "Validation Accuracy")

# Add the lower bound accuracy
plt.ylim([0.45, 1])
plt.axhline(y = 0.52, color = "black",
            label = "Base rate = 52%")
plt.xlabel("epoch")
plt.ylabel("Accuracy")
plt.title("Modeling with only Article Title as Input")
plt.legend()
plt.show()
```
![6-1.png](/images/6-1.png)

Awesome!
By the plot above, we can see that

1. **The accuracy of the first model stabilized between 92% andn 97% during training**.
2. No overfitting in the `model1` can be observed.

## Model 2: Only Article Text as Input

Now build the second model with only article text as input!

```python
# embedding the text
text_features = vectorize_layer(text_input)
text_features = embedding(text_features)

# use dropout to prevent the overfitting
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.GlobalAveragePooling1D()(text_features)
text_features = layers.Dropout(0.2)(text_features)
text_features = layers.Dense(32, activation='relu')(text_features)
text_output = layers.Dense(1, name = "fake")(text_features)
```
Now we build the `model2`, check its history and plot its accuracy.

```python
# building model
model2 = Model(
    inputs = [text_input],
    outputs = text_output
)

# compile model
model2.compile(optimizer = "adam",
               loss = losses.BinaryCrossentropy(from_logits=True),
               metrics=['accuracy']
)

# checking the model history
history2 = model2.fit(train,
                      validation_data=val,
                      epochs = 10)
```




    Epoch 1/10
    17959/17959 [==============================] - 58s 3ms/step - loss: 0.2731 - accuracy: 0.8853 - val_loss: 0.2011 - val_accuracy: 0.9176
    Epoch 2/10
    17959/17959 [==============================] - 50s 3ms/step - loss: 0.1917 - accuracy: 0.9325 - val_loss: 0.1573 - val_accuracy: 0.9396
    Epoch 3/10
    17959/17959 [==============================] - 61s 3ms/step - loss: 0.1562 - accuracy: 0.9464 - val_loss: 0.1305 - val_accuracy: 0.9619
    Epoch 4/10
    17959/17959 [==============================] - 53s 3ms/step - loss: 0.1368 - accuracy: 0.9566 - val_loss: 0.1159 - val_accuracy: 0.9673
    Epoch 5/10
    17959/17959 [==============================] - 50s 3ms/step - loss: 0.1245 - accuracy: 0.9609 - val_loss: 0.0980 - val_accuracy: 0.9735
    Epoch 6/10
    17959/17959 [==============================] - 48s 3ms/step - loss: 0.1137 - accuracy: 0.9624 - val_loss: 0.0955 - val_accuracy: 0.9739
    Epoch 7/10
    17959/17959 [==============================] - 49s 3ms/step - loss: 0.1037 - accuracy: 0.9660 - val_loss: 0.0836 - val_accuracy: 0.9759
    Epoch 8/10
    17959/17959 [==============================] - 52s 3ms/step - loss: 0.0915 - accuracy: 0.9705 - val_loss: 0.0664 - val_accuracy: 0.9813
    Epoch 9/10
    17959/17959 [==============================] - 49s 3ms/step - loss: 0.0899 - accuracy: 0.9698 - val_loss: 0.0820 - val_accuracy: 0.9566
    Epoch 10/10
    17959/17959 [==============================] - 54s 3ms/step - loss: 0.0846 - accuracy: 0.9718 - val_loss: 0.0516 - val_accuracy: 0.9857

Graph the accuracy of the training and validation, compared `model2` with the **base rate 52%**.

```python
# Plot the training accuracy
plt.plot(history2.history['accuracy'], label = "Training Set Accuracy")

# Plot the validation accuracy
plt.plot(history2.history['val_accuracy'], label = "Validation Accuracy")

# Add the lower bound accuracy
plt.ylim([0.45, 1])
plt.axhline(y = 0.52, color = "black",
            label = "Base rate = 52%")
plt.xlabel("epoch")
plt.ylabel("Accuracy")
plt.title("Modeling with only Article Text as Input")
plt.legend()
plt.show()
```
![6-2.png](/images/6-2.png)

Well done! By the plot above, we can see that

1. **The accuracy of the first model stabilized between 92、1% andn 98% during training**.
2. No overfitting in the `model2` can be observed.

## Model 3: Article Title and Text as Inputs

Now let's build the `model3` with both `title` and `text` as inputs!

**Reminder: Our goal accuracy of the best model is at least 97%!**

```python
# Merge via concatenation
both_features = layers.concatenate([title_features, text_features], axis= 1)
both_features = layers.Dense(32, activation='relu')(both_features)
both_output = layers.Dense(1, name = "fake")(both_features)

# Build model
model3 = Model(
    inputs = [title_input, text_input],
    outputs = both_output
)

# compile model
model3.compile(optimizer = "adam",
               loss = losses.BinaryCrossentropy(from_logits=True),
               metrics=['accuracy']
)

# checking the model history
history3 = model3.fit(train,
                      validation_data=val,
                      epochs = 10)
```




    Epoch 1/10
    17959/17959 [==============================] - 61s 3ms/step - loss: 0.0469 - accuracy: 0.9834 - val_loss: 0.0265 - val_accuracy: 0.9933
    Epoch 2/10
    17959/17959 [==============================] - 58s 3ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.0307 - val_accuracy: 0.9877
    Epoch 3/10
    17959/17959 [==============================] - 58s 3ms/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.0266 - val_accuracy: 0.9911
    Epoch 4/10
    17959/17959 [==============================] - 62s 3ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 0.0214 - val_accuracy: 0.9931
    Epoch 5/10
    17959/17959 [==============================] - 64s 4ms/step - loss: 0.0365 - accuracy: 0.9870 - val_loss: 0.0208 - val_accuracy: 0.9944
    Epoch 6/10
    17959/17959 [==============================] - 64s 4ms/step - loss: 0.0363 - accuracy: 0.9880 - val_loss: 0.0183 - val_accuracy: 0.9944
    Epoch 7/10
    17959/17959 [==============================] - 64s 4ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.0363 - val_accuracy: 0.9864
    Epoch 8/10
    17959/17959 [==============================] - 64s 4ms/step - loss: 0.0324 - accuracy: 0.9885 - val_loss: 0.0150 - val_accuracy: 0.9953
    Epoch 9/10
    17959/17959 [==============================] - 105s 6ms/step - loss: 0.0321 - accuracy: 0.9898 - val_loss: 0.0203 - val_accuracy: 0.9953
    Epoch 10/10
    17959/17959 [==============================] - 62s 3ms/step - loss: 0.0331 - accuracy: 0.9885 - val_loss: 0.0213 - val_accuracy: 0.9940


Now let's graph the accuracy!

```python
# Plot the training accuracy
plt.plot(history3.history['accuracy'], label = "Training Set Accuracy")

# Plot the validation accuracy
plt.plot(history3.history['val_accuracy'], label = "Validation Accuracy")

# Add the lower bound accuracy
plt.ylim([0.95, 1])
plt.axhline(y = 0.97, color = "black",
            label = "At least accuracy = 97%")
plt.xlabel("epoch")
plt.ylabel("Accuracy")
plt.title("Modeling with both Article Title and Text as Inputs")
plt.legend()
plt.show()
```
![6-3.png](/images/6-3.png)

Awesome! The `model3` looks doing great!

By the plot above, we can see that

1. **The accuracy of the first model stabilized between 98% andn 99% during training**.
2. No overfitting in the `model2` can be observed.

**It's clear that the `model3` is our best model achieving at least 97% accuracy!**

# 4. Model Evaluation

In this part, I'll test my model performance on unseen test data.

First we need to load the test data and convert it using `make_dataset()` written in Part 2. Then we evaluate the accuracy of `model3` on this dataset.

```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"
test_df = pd.read_csv(test_url)
test = make_dataset(test_df)
model3.evaluate(test)
```




    22449/22449 [==============================] - 45s 2ms/step - loss: 0.0461 - accuracy: 0.9868
    [0.04607886075973511, 0.9867700338363647]

The `model3` got 98.67% accuracy on the test set, good job!

# 5. Embedding Visualization

In this part, I would like to visualize and comment on the *embedding* that the `model3` learned. 

```python
# get the weights from the embedding layer
weights = model3.get_layer('embedding').get_weights()[0] 
# get vocabulary
vocab = vectorize_layer.get_vocabulary()  
```

```python
weights
```




    array([[ 0.01088121,  0.01214439,  0.01224524],
        [ 0.18024087,  0.04601349, -1.779594  ],
        [-5.7066426 , -5.974835  ,  5.823497  ],
        ...,
        [-3.4415512 , -3.4015346 ,  4.1883807 ],
        [-3.3735764 , -3.907295  ,  4.8797507 ],
        [ 0.9753655 ,  0.96969104,  0.68162334]], dtype=float32)

As we can see, the collection of weights is 3-dimensional. For plotting in 2-dimensions, I use principal component analysis(PCA) to reduce the data to a 2d representation.

```python
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
weights = pca.fit_transform(weights)
```
Now I'll make a dataframe from the result.

```python
embedding_df = pd.DataFrame({
    'word' : vocab, 
    'x0'   : weights[:,0],
    'x1'   : weights[:,1]
})
embedding_df
```
{% include 6-4.html %}

Now it's ready to plot!

```python
import numpy as np
import plotly.express as px 
fig = px.scatter(embedding_df, 
                 x = "x0", 
                 y = "x1",
                 size = list(np.ones(len(embedding_df))),
                 size_max = 3,
                 hover_name = "word").update_traces(marker=dict(color='blue'))

fig.show()
```
{% include 6-5.html %}

Looks good! This embedding seems to have learned some reasonable associations. 

Now let's try to figure out at least 5 words whose location in the embedding.

I thought the words about the verbs in our model associate with `democrat` and `republican` might be interested.

```python
from dataclasses import replace
dem = ["democrat"]
rep = ["republican"]

highlight_1 = ["win", "lose", "defeat", "success"]
highlight_2 = ["believe", "help", "care", "trust"]

def mapper(x):
    if x in dem:
        return 1
    elif x in rep:
        return 4
    elif x in highlight_1:
        return 3
    elif x in highlight_2:
        return 2
    else:
        return 0

embedding_df["highlight"] = embedding_df["word"].apply(mapper)
embedding_df["size"] = np.array(1.0 + 50*(embedding_df["highlight"] > 0))

fig = px.scatter(embedding_df, 
                 x = "x0", 
                 y = "x1", 
                 color = "highlight",
                 size = list(embedding_df["size"]),
                 size_max = 20,
                 hover_name = "word")

fig.show()
```
{% include 6-5.html %}

We can see that
- the words "republican" is far away from the other words
- the word "democrat" is close to the word "win", "lose", "defeat", "success", "believe", "help", "care", "trust"

This indicates that our model is biased.

This bias might be caused by Joe Biden's victory as the president-elect. 

In this case, our model needs further fixing in the future.