---
layout: post
title: Blog Post 3
---

In this Blog Post, I will use webscraping to answer the following question:

>What movie or TV shows share actors with my favorite movie, **Harry Potter and the Sorcerer's Stone**?

This post has two parts. In the first part, I'll write a webscraper to find shared actors on IMDB. In the second part, I'll use my webscraper to make recommendations.

# Setup

Following the steps in `Part 1` of the assignment prompt, I create my own WebScraper repository including all the code in the next part.

The assignment prompt link is https://www.philchodrow.com/PIC16B//posts/blog-post-scrape.

My WebScraper GitHub Repository link is https://github.com/JiyuanLyu/pic-webscraper.

## Locate the Starting IMDB Page

My favorite movie is **Harry Potter and the Sorcerer's Stone**. Its IMDB page is at https://www.imdb.com/title/tt0241527/.

## Initialize the project

After creating the Github repository, open the terminal in the location of the repository on the laptop, type the following code to help initialize the project.

```python
conda activate PIC16B
scrapy startproject IMDB_scraper
cd IMDB_scraper
```

Remember to add this line in the file `settings.py` to prevent the scraper from downloading too much data while testing things out.

```python
CLOSESPIDER_PAGECOUNT = 20
```
I'll remove this line after constructing the webscraper.

# Webscraper

In this part, I'll write a webscraper to answer the question of this project:

>What movie or TV shows share actors with my favorite movie, **Harry Potter and the Sorcerer's Stone**?

First of all, I import necessary packages and write a class called `ImdbSpider` to scrape the information of actors. The scraper start from the starting IMDB website.


```python
# This is the package for writing webscraper
import scrapy
# This is the package will be used in
# `parse_actor_page(self, response)`
from gettext import find 

# Write the class and define the starting page
class ImdbSpider(scrapy.Spider):
    name = 'imdb_spider'
    
    start_urls = ['https://www.imdb.com/title/tt0241527/']
```

## `parse(self, response)`

In the `ImdbSpider` class, I write a method navigates to the `Cast & Crew` page from the starting movie page, and then calls the function `parse_full_credits(self, response)`. 

This method will do three things:

1. navigates to the `Cast & Crew` page
2. should not return any data and yield to `scrapy.Request`
3. call the `parse_full_creadits()` method

The code are shown below.

```python
def parse(self, response):
    """
    This function navigates to the `Cast & Crew` page
    from the starting movie page, and then calls the function
    `parse_full_credits(self, response)`.
    """

    # Navigates to the `Cast & Crew` page
    castcrew = response.urljoin("fullcredits")

    # Call function in the `callback` argument to 
    # a yielded `scrapy.Request`
    yield scrapy.Request(castcrew,
                         callback = self.parse_full_credits)
```

## `parse_full_credits(self, response)`

Here, I write a method navigates to the `Actor` page from the `Cast & Crew` page and creates a list of relative paths for each actors, and then calls the function `parse_actor_page(self, response)` when each actor's page is reached. 

This method will do three things:

1. navigates to the actor's page for each actor by clicking the primary photo
2. should not return any data and yield to `scrapy.Request`
3. call the `parse_actor_page()` method

The code are shown below.

```python
def parse_full_credits(self, response):
    """
    This function yield a `scrapy.Request` for the page of 
    each actor listed on the `Cast & Crew` page.
    Call the method `parse_actor_page(self_response)` when
    reaching the actors' pages.
    """

    # Click the actors' headshots using the hint
    actors = [a.attrib["href"] for a in response.css("td.primary_photo a")]
    # For each actor, yield a request
    for actor in actors:
        actor_page = "https://www.imdb.com/" + actor
        yield scrapy.Request(actor_page,
                             callback = self.parse_actor_page)
```

## `parse_actor_page(self, response)`

This method assumes that it start on the page of an actor. It should yield a two-key value dictionary for each of the movies or TV shows on which that actor has worked.

During the process, I noticed that there are some trivial names which will be counted as shows. Thus I use `find()` from `gettext` package to get rid of the names including "Episode" or "Show all".

This method will do three things:

1. collect all the movies or TV shows in the actor's page
2. get rid of collected "Episode" or "Show all" which will mess up the recommendations
3. yield a two-key value dictionary as `{"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}`

The code are shown below.

```python
def parse_actor_page(self, response):
    """
    This function yield a dictionary of two key-value pairs as
    {"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}
    from the page of the actor.
    """

    # Get the first value in the dictionary: actor_name
    actor_name = response.css("span.itemprop::text").get()

    # Then, get the second value in the dictionary: movie_or_TV_name
    # Get all the filmography of this actor
    movies = response.css("div.filmo-row b a::text").getall()
    for movie_name in movies:
        # Here, to get rif of the trivial names,
        # I'll not include the show names including
        # "Episode" or "Show all"
        if (movie_name.find("Episode" and "Show all") == -1):
            yield {"actor": actor_name, "movie_or_TV_name": movie_name}
```

>Good job! We just finished contructing the `WebScraper`! 

## Scraping the Movie Data

Before scraping, comment out this line in `settings.py`:

```python
CLOSESPIDER_PAGECOUNT = 20
```

Now, let's save a CSV file called `results.csv` including columns for actor names and the movies and TV shows on which they worked.

```python
scrapy crawl imdb_spider -o results.csv
```

Awesome! Now we can create the recommendation dataframe based on this `result.csv`!

# Recommendations

In this part, I use the `pandas` package in python and modify the `results.csv` from the last part to a pandas dataframe of recommendated movies. The codes are shown below.

```python
# Import the package and the csv file
import pandas
data = pandas.read_csv("results.csv")

# Here I drop the actor column since only the movie column is needed
movie = data.drop(['actor'], axis = 1)

# And then I make recommendations based on the frequency
# of these movies or shows
recommendations = movie.value_counts().rename_axis(
    "Movie or TV show").reset_index(name = 'Number of Shared Actors')
```

The `recommendations` is the dataframe listing the movies and TV shows that share actors with **Harry Potter and the Sorcerer's Stone**. The interactive dataframe is shown below.

{% include recommendation.html %}